{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from keras import models, layers, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(64,))\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "#only now put the pieces together into a model leading from input to output\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# compile and fit as usual\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accurcy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiple inputs example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example 1: CNN to process image input, RNN to process text input\n",
    "You work for an online store that sells clothing, like Etsy. You want to fit a model with the following specifications:\n",
    "Inputs:\n",
    "• a picture of a piece of clothing\n",
    "• a text description of the clothing\n",
    "Outputs:\n",
    "• estimated sale price\n",
    "\n",
    "We could use a network architecture like:\n",
    "• a CNN to process the picture\n",
    "• an RNN to process the text description\n",
    "• combine activation output from the CNN and RNN\n",
    "• dense output layer to predict price"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example 2: RNN to process two different text inputs\n",
    "You work at a tech company, and are developing a user help page that will answer users’ questions based on help\n",
    "documentation. You want to fit a model with the following specifications:\n",
    "Inputs:\n",
    "• a text question a user typed\n",
    "• text of relevant help articles\n",
    "Outputs:\n",
    "• answer to the question, which is one of K categories (for example, K-1 possible solutions, or else send them to a\n",
    "human being to answer the question.)\n",
    "We could use a network architecture like:\n",
    "• a first RNN to process the question\n",
    "• a second RNN to process the text with the answers\n",
    "• feed the output from the RNNs into a dense layer to generate a predicted class for the answer.\n",
    "\n",
    "<img src=\"data/example.jpg\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers, Input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# first input layer is a text sequence.\n",
    "# - We don't specify the length since it may differ across observations\n",
    "# - data type is integer because we sparse-encoded the text\n",
    "# - we can give the input layer a name if we want\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "\n",
    "# 64 dimensional word embedding of text input\n",
    "embedding_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "\n",
    "# LSTM to process text\n",
    "encoded_text = layers.LSTM(32)(embedding_text)\n",
    "\n",
    "#**************\n",
    "\n",
    "# second input layer is the question; same structure as for text input\n",
    "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
    "\n",
    "# 32 dimensional word embedding of question input\n",
    "embedding_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "\n",
    "# LSTM to process question\n",
    "encoded_question = layers.LSTM(16)(embedding_question)\n",
    "\n",
    "# concatenate the activation outputs from the text LSTM and the question LSTM\n",
    "# axis = -1 means to concatenate along the last axis.\n",
    "\n",
    "concateneted = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# the answer is one of a fixed number of categories.\n",
    "# probabilities for these categories are calculated using a softmax activation\n",
    "# acting on the concatenated output from the question and the reference text\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concateneted)\n",
    "\n",
    "# The network now has two inputs!!\n",
    "model = Model(inputs=[text_input, question_input], outputs=answer)\n",
    "\n",
    "# Compile as usual\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# To fit, provide a dictionary with the values of the inputs\n",
    "# names in the dictionary must match the names used when defining the layers\n",
    "model.fit({'test': text, 'question': question}, answeres, epochs=10, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
